{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './test_data.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    loaded_test_data = pickle.load(f)\n",
    "\n",
    "test_loader = loaded_test_data[\"test_loader\"]\n",
    "label_to_index = loaded_test_data[\"label_to_index\"]\n",
    "attack_types_list = loaded_test_data[\"attack_types_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        feature_vector = out[:,-1,:]\n",
    "        out = self.fc2(feature_vector)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out) ## 128\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc4(out)\n",
    "\n",
    "        return out, feature_vector\n",
    "\n",
    "    def get_features(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return out[:,-1,:]\n",
    "\n",
    "input_dim = 10  \n",
    "hidden_dim = 256 \n",
    "num_layers = 4  \n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction_LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(FeatureExtraction_LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout with 50% drop probability\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        feature_vector = out[:,-1,:]\n",
    "        out = self.fc2(feature_vector)\n",
    "        return out, feature_vector\n",
    "\n",
    "    def get_features(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return out[:,-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = 256\n",
    "        self.hidden_size = 256\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size//2)\n",
    "        self.fc3 = nn.Linear(self.hidden_size//2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lstm_model = LSTMClassifier(input_dim, hidden_dim, num_layers, 20).to(device)\n",
    "hiera_model_save_path = './models/'\n",
    "num_classes = len(attack_types_list) \n",
    "hierarchical_models = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_saved_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "file_path = './models/hierachical_models.pkl'\n",
    "loaded_data = load_saved_data(file_path)\n",
    "\n",
    "hierarchical_models = loaded_data[\"hierarchical_models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "class HierarchicalClassifier:\n",
    "    def __init__(self, device, hierarchical_models, attack_label_to_index):\n",
    "        self.device = device\n",
    "        self.hierarchical_models = hierarchical_models\n",
    "        self.attack_label_to_index = attack_label_to_index\n",
    "        \n",
    "        self.models_cache = {}\n",
    "        for group_name, info in self.hierarchical_models.items():\n",
    "            model_info = info[0] \n",
    "            lbl2idx = model_info['label_to_index']\n",
    "            idx2lbl = {v: k for k, v in lbl2idx.items()}\n",
    "            \n",
    "            self.models_cache[group_name] = {\n",
    "                'model': model_info['model'],\n",
    "                'lbl2idx': lbl2idx,\n",
    "                'idx2lbl': idx2lbl,\n",
    "                'is_one_class': model_info['is_one_class'],\n",
    "            }\n",
    "    \n",
    "    def classify(self, batch_seq):\n",
    "        batch_seq = batch_seq.to(self.device)\n",
    "        combined_info = self.models_cache['combined']\n",
    "        combined_model = combined_info['model']\n",
    "        combined_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_group_scores, feature_vectors = combined_model(batch_seq)\n",
    "        _, group_nums = torch.max(pred_group_scores, dim=1)\n",
    "        batch_size = batch_seq.size(0)\n",
    "        batch_predictions = [None] * batch_size\n",
    "\n",
    "        group_to_indices = defaultdict(list)\n",
    "        for i, gnum in enumerate(group_nums):\n",
    "            group_to_indices[gnum.item()].append(i)\n",
    "\n",
    "\n",
    "        for gnum, indices in group_to_indices.items():\n",
    "            group_name = combined_info['idx2lbl'][gnum]\n",
    "\n",
    "            group_info = self.models_cache[group_name]\n",
    "            group_model = group_info['model']\n",
    "            group_lbl2idx = group_info['lbl2idx']\n",
    "            group_idx2lbl = group_info['idx2lbl']\n",
    "            group_is_one_class = group_info['is_one_class']\n",
    "\n",
    "            if group_is_one_class:\n",
    "                only_label = list(group_lbl2idx.keys())[0]\n",
    "                only_label_idx = self.attack_label_to_index[only_label]\n",
    "                for i in indices:\n",
    "                    batch_predictions[i] = only_label_idx\n",
    "            else:\n",
    "                group_features = feature_vectors[indices]  # (len(indices), feature_dim)\n",
    "                group_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    pred_scores = group_model(group_features)\n",
    "                _, pred_label_idx = torch.max(pred_scores, dim=1)\n",
    "\n",
    "                for i, lbl_idx in zip(indices, pred_label_idx):\n",
    "                    lbl_idx_int = lbl_idx.item()\n",
    "                    final_label_str = group_idx2lbl[lbl_idx_int]\n",
    "                    final_label_idx = self.attack_label_to_index[final_label_str]\n",
    "                    batch_predictions[i] = final_label_idx\n",
    "\n",
    "        return batch_predictions\n",
    "classifier = HierarchicalClassifier(device, hierarchical_models, label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def atk_find_key(dictionary, values):\n",
    "    labels = []\n",
    "    for i in values:\n",
    "        for k,v in dictionary.items():\n",
    "            if v == i:\n",
    "                labels.append(k)\n",
    "    return labels\n",
    "\n",
    "def get_metrics_from_cm(cm, class_names):\n",
    "    true_labels = cm.sum(axis=1)\n",
    "    predicted_labels = cm.sum(axis=0)\n",
    "    \n",
    "    precision = np.diag(cm) / predicted_labels\n",
    "    recall = np.diag(cm) / true_labels\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Label': class_names,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_scores\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def evaluate_model_batchwise(data_loader, classifier, device):\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_seq, batch_labels in tqdm(data_loader, desc=\"Evaluating multi-class\"):\n",
    "            batch_seq = batch_seq.to(device)\n",
    "            preds = classifier.classify(batch_seq)\n",
    "            if isinstance(preds, torch.Tensor):\n",
    "                preds = preds.cpu().numpy()\n",
    "            all_predictions.extend(preds)\n",
    "            all_true_labels.extend(batch_labels.cpu().numpy())\n",
    "            total_samples += batch_seq.size(0)\n",
    "\n",
    "\n",
    "    acc = accuracy_score(all_true_labels, all_predictions)\n",
    "    f1 = f1_score(all_true_labels, all_predictions, average='macro')\n",
    "    precision_macro = precision_score(all_true_labels, all_predictions, average='macro')\n",
    "    recall_macro = recall_score(all_true_labels, all_predictions, average='macro')\n",
    "    cm_multi = confusion_matrix(all_true_labels, all_predictions)\n",
    "\n",
    "    return acc, f1, precision_macro, recall_macro, cm_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1, precision_macro, recall_macro, cm= evaluate_model_batchwise(test_loader, classifier, device)\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "print(f\"precision: {precision_macro:.4f}, recall: {recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_metrics_from_cm(cm, attack_types_list)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
